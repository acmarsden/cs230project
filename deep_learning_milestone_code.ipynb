{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "#import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = np.loadtxt('X_train.csv', delimiter=',')\n",
    "X_dev = np.loadtxt('X_dev.csv',delimiter=',')\n",
    "X_test = np.loadtxt('X_test.csv',delimiter=',')\n",
    "Y_train = np.loadtxt('Y_train.csv', delimiter=',')\n",
    "Y_dev = np.loadtxt('Y_dev.csv', delimiter=',')\n",
    "Y_test = np.loadtxt('Y_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_train = np.reshape(Y_train, (1, 5000))\n",
    "Y_dev = np.reshape(Y_dev, (1, 1070))\n",
    "Y_test = np.reshape(Y_test, (1, 1067))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 5000\n",
      "number of dev examples = 1070\n",
      "number of test examples = 1067\n",
      "X_train shape: (939, 5000)\n",
      "Y_train shape: (1, 5000)\n",
      "X_dev shape: (939, 1070)\n",
      "Y_dev shape: (1, 1070)\n",
      "X_test shape: (939, 1067)\n",
      "Y_test shape: (1, 1067)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of dev examples = \" + str(X_dev.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_dev shape: \" + str(X_dev.shape))\n",
    "print (\"Y_dev shape: \" + str(Y_dev.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's just try with activate/no activate\n",
    "Y_train = 1.0*(Y_train!=0)\n",
    "Y_dev = 1.0*(Y_dev!=0)\n",
    "Y_test = 1.0*(Y_test!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of a small molecule vector (939)\n",
    "    n_y -- scalar = 1\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    " \n",
    "    \"\"\"\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x, None], name = \"X\")\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None], name = \"Y\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 939]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [1, 12]\n",
    "                        b3 : [1, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)               \n",
    "        \n",
    "    W1 = tf.get_variable(\"W1\", [25,939], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                              \n",
    "    A1 = tf.nn.relu(Z1)                                             \n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                            \n",
    "    A2 = tf.nn.relu(Z2)                                             \n",
    "    Z3 = tf.sigmoid(tf.add(tf.matmul(W3,A2),b3))                                        \n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (1, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    scale = 60; \n",
    "    eps = 10e-3\n",
    "    logits = tf.transpose(Z3) \n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    #cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = labels, logits = logits))\n",
    "    #cost = tf.add(tf.reduce_mean(tf.nn.l2_loss(Z3-Y)), tf.reduce_mean(tf.nn.l2_loss(tf.multiply(Y,Z3-Y))))\n",
    "    cost = -tf.reduce_mean(tf.add(scale*tf.multiply(labels, tf.log(logits+eps)), tf.multiply(1-labels, tf.log(1-logits+eps))))\n",
    "    #cost = tf.reduce_mean(tf.multiply(labels, tf.log(logits+eps)))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Neg:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(939,1)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.01,\n",
    "          num_epochs = 2300, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    \n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        \n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_1:0\", shape=(939, ?), dtype=float32)\n",
      "Y = Tensor(\"Y_1:0\", shape=(1, ?), dtype=float32)\n",
      "Cost after epoch 0: 3.838337\n",
      "Cost after epoch 100: 1.012507\n",
      "Cost after epoch 200: 0.745185\n",
      "Cost after epoch 300: 0.606641\n",
      "Cost after epoch 400: 0.549458\n",
      "Cost after epoch 500: 0.464942\n",
      "Cost after epoch 600: 0.405751\n",
      "Cost after epoch 700: 0.370832\n",
      "Cost after epoch 800: 0.352667\n",
      "Cost after epoch 900: 0.333823\n",
      "Cost after epoch 1000: 0.321965\n",
      "Cost after epoch 1100: 0.302055\n",
      "Cost after epoch 1200: 0.285988\n",
      "Cost after epoch 1300: 0.329244\n",
      "Cost after epoch 1400: 0.314216\n",
      "Cost after epoch 1500: 0.306788\n",
      "Cost after epoch 1600: 0.293427\n",
      "Cost after epoch 1700: 0.282986\n",
      "Cost after epoch 1800: 0.325389\n",
      "Cost after epoch 1900: 0.315707\n",
      "Cost after epoch 2000: 0.309847\n",
      "Cost after epoch 2100: 0.304705\n",
      "Cost after epoch 2200: 0.300240\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122de7410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "('Train Accuracy:', 1.0)\n",
      "('Test Accuracy:', 1.0)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(939, 1)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(939,1)\n",
    "    Z_train = sess.run(forward_propagation(X, parameters), feed_dict={X: X_train})\n",
    "    Z_dev = sess.run(forward_propagation(X, parameters), feed_dict={X: X_dev})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train Accuracy on Negative Examples:', 0.94839549002601908)\n",
      "('Dev Accuracy on Negative Examples:', 0.9144869215291751)\n",
      "('Train Accuracy on Positive Examples:', 0.99484536082474229)\n",
      "('Dev Accuracy on Positive Examples:', 0.75)\n"
     ]
    }
   ],
   "source": [
    "P_train = Z_train >= 0.5\n",
    "P_dev = Z_dev>=0.5\n",
    "\n",
    "err_train = np.abs(P_train - Y_train)\n",
    "err_dev = np.abs(P_dev - Y_dev)\n",
    "\n",
    "# Error on the negative train examples\n",
    "n_negative_train = (Y_train == 0).sum()\n",
    "print(\"Train Accuracy on Negative Examples:\",1-np.abs(err_train[Y_train == 0]).sum()/n_negative_train)\n",
    "\n",
    "# Error on the negative dev examples\n",
    "n_negative = (Y_dev == 0).sum()\n",
    "print(\"Dev Accuracy on Negative Examples:\", 1-np.abs(err_dev[Y_dev == 0]).sum()/n_negative)\n",
    "\n",
    "# Error on the positive train examples\n",
    "n_positive_train = (Y_train != 0).sum()\n",
    "print(\"Train Accuracy on Positive Examples:\", 1-np.abs(err_train[Y_train !=0]).sum()/n_positive_train)\n",
    "\n",
    "# Error on the positive dev examples\n",
    "n_positive = (Y_dev != 0).sum()\n",
    "print(\"Dev Accuracy on Positive Examples:\", 1-np.abs(err_dev[Y_dev !=0]).sum()/n_positive)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
